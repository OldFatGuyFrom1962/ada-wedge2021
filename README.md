# ada-wedge2021
# Applied Data Analytics

## Wedge Project

<!-- My understanding of the process and coding to perform Task 1a-c was much more clear than last year
 given the time I spent reviewing lectures and actually coding the variations presented (ie, find best option)--> 

### Task 1

* Files for this task: 
`File1 Name`: Wedge task 1a - determine if headers in full CSVs
reviews and prints to screen 1st row of each of the 52 csv's; used to see which had headers (NOT 201511 thru 201701)

`File1 Name`: Wedge task 1b-i clean delimiters and nulls and bad field counts 8 bad files
Sets common delimiter, fixes null values and IDENTIFIES file/record combinations with OTHER than 50 fields (8 files)

`File1 Name`: Wedge task 1b-ii clean delimiters and nulls and identify bad field counts
tested process to concatenate 3 comma-delimited fields into 1 field

`File1 Name`: Wedge task 1b-iii proof cleanup and element counts
Code to do all of 1b above and confirm all csv files of concern have 50 columns of data

`File1 Name`: Wedge task 1c - extract from zipped - clean - populate CSVs to new folder
Code to extract FROM zip, clean and then populate csv TO clean folder

`File1 Name`: Wedge task 1d FULL DATA
Loads all data into GBQ data set.

### Task 2

* Files for this task: 

`File1 Name`: Wedge Task2
Notebook which identifies a sample of owners and extracts all transactions for sample into a text file

<!--  Repeat for each file  --> 
	

### Task 3

* Files for this task: 

`File1 Name`: Wedge Task3
Notebook which codes the three required queries, creates text files and populates them to .db database file


## Query Comparison Results

Fill in the following table with the results from the 
queries contained in `gbq_assessment_query.sql`. You only
need to fill in relative difference on the rows where it applies. 
When calculating relative difference, use the formula 
` (your_results - my_results)/my_results)`. 



|  Query  |  Your Results  |  My Results | Difference | Rel. Diff | 
|---|---|---|---|---|
| Total Rows  |85760139|85760139|0|0.0|
| January 2012 Rows  |1070907|1070907|0|0.0|
| October 2012 Rows  |1042287|1042287|0|0.0|
| Month with Fewest  |Feb|Feb| No  | NA  |
| Num Rows in Month with Fewest  |6556770|6556770|0|0.0|
| Month with Most  |May|May| No  | NA  |
| Num Rows in Month with Most  |7578372|7578372|0|0.0|
| Null_TS  |7123792|7123792|0|0.0|
| Null_DT  |0|0|0|0.0|
| Null_Local  |234843|234843|0|0.0|
| Null_CN  |0|0|0|0.0|
| Num 5 on High Volume Cards  |14987|14987| No  | NA  |
|  Num Rows for Number 5 |460630|460630|0|0.0|
| Num Rows for 18736  |12153|12153|0|0.0|
| Product with Most Rows  |banana organic|banana organic|No  | NA  |
| Num Rows for that Product  |908639|908639|0|0.0|
| Product with Fourth-Most Rows  |avocado hass organic|avocado hass organic| No  | NA  |
| Num Rows for that Product  |456771|456771|0|0.0|
| Num Single Record Products  |2769|2769|0|0.0|
| Year with Highest Portion of Owner Rows  |2014|2014| No  | NA |
| Fraction of Rows from Owners in that Year  |0.7591|0.7591|0|0.0|
| Year with Lowest Portion of Owner Rows  |2011|2011| No  | NA |
| Fraction of Rows from Owners in that Year  |0.7372|0.7372|0|0.0|

## Reflections

<!-- I enjoyed working on the Wedge much more this year than last, mostly due to actually learning the python and SQL needed --> 
